{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90b219ee",
   "metadata": {
    "id": "90b219ee"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.models import Sequential,Model\n",
    "from tensorflow.keras.layers import Conv2D,LeakyReLU,Dense,Flatten,Reshape,Dropout,UpSampling2D,Embedding,Concatenate\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from tensorflow.keras.preprocessing.image import array_to_img\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00774123",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "00774123",
    "outputId": "f701bfcf-c6a5-4c45-a090-49f3d3ebf134"
   },
   "outputs": [],
   "source": [
    "(X_ds,_),(Y_ds,_) = fashion_mnist.load_data() # getting only X_train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb0e9f5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2fb0e9f5",
    "outputId": "0431f1c2-a190-40e7-def1-1e23ee80d800"
   },
   "outputs": [],
   "source": [
    "X_ds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3649acec",
   "metadata": {
    "id": "3649acec"
   },
   "outputs": [],
   "source": [
    "# X_ds = tf.convert_to_tensor(X_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d56064",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 596
    },
    "id": "e6d56064",
    "outputId": "bce65356-baf0-4bcf-c751-fd3da0442673"
   },
   "outputs": [],
   "source": [
    "# visualizing dataset\n",
    "fig,ax = plt.subplots(ncols=4,figsize=(20,20))\n",
    "\n",
    "for idx in range(4):\n",
    "    ax[idx].imshow(np.squeeze(X_ds[idx]))\n",
    "    ax[idx].title.set_text(Y_ds[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0d554b",
   "metadata": {
    "id": "9b0d554b"
   },
   "outputs": [],
   "source": [
    "X_ds = X_ds/255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025a64ab",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "025a64ab",
    "outputId": "4aa06ce3-bf7e-423d-ea0c-e9370efe1b37",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad77e5f1",
   "metadata": {
    "id": "ad77e5f1"
   },
   "source": [
    "### Building Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0337b22c",
   "metadata": {
    "id": "0337b22c"
   },
   "source": [
    "#### Building Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60962b97",
   "metadata": {
    "id": "60962b97"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3aad9dc",
   "metadata": {
    "id": "b3aad9dc"
   },
   "outputs": [],
   "source": [
    "# we need (28,28,1) shaped images generated by generator\n",
    "def build_generator(n_classes=10):\n",
    "    in_label = Input(shape=(1,))\n",
    "    li = Embedding(n_classes,50)(in_label)\n",
    "    li = Dense(7*7)(li)  # match dimension for concat later\n",
    "    li = Reshape((7,7,1))(li)\n",
    "    \n",
    "    in_lat = Input(shape=(128,))\n",
    "    \n",
    "\n",
    "    gen = Dense(7*7*128)(in_lat) # we will pass array of noise with 128 dim\n",
    "    gen = LeakyReLU(0.2)(gen)\n",
    "    gen = Reshape((7,7,128))(gen)\n",
    "    \n",
    "    # concatanating image and label input\n",
    "    merge = Concatenate()([gen,li])\n",
    "    \n",
    "    # Upsampling block -> (we need (28,28,1) images)\n",
    "    gen = UpSampling2D()(merge)   ## doubles the size of image (7,7,128) -> (14,14,128)\n",
    "    gen = Conv2D(128,5,padding='same')(gen)\n",
    "    gen = LeakyReLU(0.2)(gen)\n",
    "\n",
    "    # Upsampling block 2\n",
    "    gen = UpSampling2D()(gen)\n",
    "    gen = Conv2D(128,5,padding='same')(gen)\n",
    "    gen = LeakyReLU(0.2)(gen)\n",
    "\n",
    "    # Covolution block 1\n",
    "    gen = Conv2D(128,4,padding='same')(gen)\n",
    "    gen = LeakyReLU(0.2)(gen)\n",
    "\n",
    "    # convolution block 2\n",
    "    gen = Conv2D(128,4,padding='same')(gen)\n",
    "    gen = LeakyReLU(0.2)(gen)\n",
    "\n",
    "    ## conv layer to get 1 channel\n",
    "    out = Conv2D(1,4,padding='same',activation='sigmoid')(gen)\n",
    "    \n",
    "    model = Model([in_lat,in_label],out)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4758f9",
   "metadata": {
    "id": "8d4758f9"
   },
   "outputs": [],
   "source": [
    "generator  = build_generator()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f14ae2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "48f14ae2",
    "outputId": "24319664-4037-45d9-e116-e8050366cad4"
   },
   "outputs": [],
   "source": [
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef6771e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 193
    },
    "id": "1ef6771e",
    "outputId": "60bf4d10-c7bb-41c0-bfc1-fcc4520e6986"
   },
   "outputs": [],
   "source": [
    "## generating new images using generator\n",
    "img = generator.predict(np.random.randn(4,128,1)) #  4images of size (128,1)\n",
    "\n",
    "fig,ax = plt.subplots(ncols=4,figsize=(20,20))\n",
    "\n",
    "for i,img in enumerate(img):\n",
    "    ax[i].imshow(np.squeeze(img))\n",
    "    ax[i].title.set_text((i))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef9ade66",
   "metadata": {
    "id": "ef9ade66"
   },
   "source": [
    "### Building Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd95594",
   "metadata": {
    "id": "6bd95594"
   },
   "outputs": [],
   "source": [
    "def  build_discriminator(n_classes=10):\n",
    "    \n",
    "    in_label = Input(shape=(1,))\n",
    "    \n",
    "    li = Embedding(n_classes,50)(in_label)\n",
    "    li = Dense(784)(li)  # size of input image\n",
    "    li = Reshape((28,28,1))(li) \n",
    "    \n",
    "    in_image = Input(shape=(28,28,1))\n",
    "    merge = Concatenate()([in_image,li])\n",
    "    \n",
    "    \n",
    "    fe = Conv2D(32,5)(merge)\n",
    "    fe = LeakyReLU(0.2)(fe)\n",
    "    fe = Dropout(0.4)(fe)\n",
    "\n",
    "    fe = Conv2D(64,5)(fe)\n",
    "    fe = LeakyReLU(0.2)(fe)\n",
    "    fe = Dropout(0.4)(fe)\n",
    "\n",
    "    fe = Conv2D(128,5)(fe)\n",
    "    fe = LeakyReLU(0.2)(fe)\n",
    "    fe = Dropout(0.4)(fe)\n",
    "\n",
    "    fe = Conv2D(256, 5)(fe)\n",
    "    fe = LeakyReLU(0.2)(fe)\n",
    "    fe = Dropout(0.4)(fe)\n",
    "\n",
    "    fe = Flatten()(fe)\n",
    "    fe = Dropout(0.4)(fe)\n",
    "    out = Dense(1,activation='sigmoid')(fe)\n",
    "    \n",
    "    model = Model([in_image,in_label],out)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb198a74",
   "metadata": {
    "id": "cb198a74"
   },
   "outputs": [],
   "source": [
    "discriminator = build_discriminator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6904707e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6904707e",
    "outputId": "d5af6479-69d9-409d-960e-ef433bba2e43"
   },
   "outputs": [],
   "source": [
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4d18d8",
   "metadata": {
    "id": "de4d18d8"
   },
   "outputs": [],
   "source": [
    "img = generator(tf.random.uniform((4,128,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85dbb4b5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "85dbb4b5",
    "outputId": "673ec3ff-ae85-4dc2-f366-14b1c9ce25bf"
   },
   "outputs": [],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c6fe06",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "70c6fe06",
    "outputId": "c384c0eb-6f6a-495c-fa9a-5898c99554c5"
   },
   "outputs": [],
   "source": [
    "discriminator.predict(np.expand_dims(img[0],axis=0)) # as we didn't train generator or discriminator it is giving random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f9b359",
   "metadata": {
    "id": "a5f9b359"
   },
   "source": [
    "### Custom Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40012c20",
   "metadata": {
    "id": "40012c20"
   },
   "outputs": [],
   "source": [
    "g_opt = Adam(0.0001)\n",
    "d_opt = Adam(0.00001)\n",
    "g_loss = BinaryCrossentropy()\n",
    "d_loss = BinaryCrossentropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf83f80",
   "metadata": {
    "id": "2cf83f80"
   },
   "outputs": [],
   "source": [
    "class FashionGAN(Model):\n",
    "\n",
    "    def __init__(self,generator,discriminator,*args,**kwargs):\n",
    "        super().__init__(*args,**kwargs)\n",
    "\n",
    "        ## creating attributes for generator and discriminator\n",
    "        self.generator = generator\n",
    "        self.discriminator = discriminator\n",
    "\n",
    "    def compile(self,g_opt,d_opt,g_loss,d_loss,*args,**kwargs):\n",
    "        ## compiling with base class\n",
    "        super().compile(*args,**kwargs)\n",
    "\n",
    "        ## attributes for losses and optimizers\n",
    "        self.g_opt = g_opt\n",
    "        self.d_opt = d_opt\n",
    "        self.g_loss = g_loss\n",
    "        self.d_loss = d_loss\n",
    "\n",
    "    def train_step(self,batch):\n",
    "        print(batch.shape)\n",
    "        real_images = batch\n",
    "        # generating 128 noise vector of size (128,1) and pass it to generator\n",
    "        fake_images = self.generator(tf.random.normal((128,128,1)),training=False)\n",
    "\n",
    "        ## training discriminator first\n",
    "        with tf.GradientTape() as d_tape:\n",
    "            # pass the real and fake images in discriminator\n",
    "            y_hat_real = self.discriminator(real_images,training=True)\n",
    "            y_hat_fake = self.discriminator(fake_images,training=True)\n",
    "            # concatinating real and fake output\n",
    "            y_hat_realfake = tf.concat([y_hat_real,y_hat_fake],axis=0)\n",
    "\n",
    "            ## creating labels for real and fake images\n",
    "            y_real_fake = tf.concat([tf.zeros_like(y_hat_real),tf.ones_like(y_hat_fake)],axis=0)\n",
    "\n",
    "            ## adding random noise in y_real_fake\n",
    "            noise_real = 0.15*tf.random.uniform(tf.shape(y_hat_real))\n",
    "            noise_fake = -0.15*tf.random.uniform(tf.shape(y_hat_fake))\n",
    "            y_real_fake += tf.concat([noise_real,noise_fake],axis=0)\n",
    "\n",
    "            ## calculating discriminator loss\n",
    "            total_d_loss = self.d_loss(y_real_fake,y_hat_realfake)\n",
    "\n",
    "        ## Applying Backpropogation\n",
    "        dgrad = d_tape.gradient(total_d_loss,self.discriminator.trainable_variables)\n",
    "        self.d_opt.apply_gradients(zip(dgrad,self.discriminator.trainable_variables))\n",
    "\n",
    "         ### Now Train the generator\n",
    "        with tf.GradientTape() as g_tape:\n",
    "            # generate image\n",
    "            gen_images = self.generator(tf.random.normal((128,128,1)),training=True)\n",
    "\n",
    "            ## Predicting labels using generator making its training =False\n",
    "            predicted_labels = self.discriminator(gen_images,training=False)\n",
    "\n",
    "            ## Calculating g_loss, here making discriminator fool by givin 0's as real y\n",
    "            total_g_loss = self.g_loss(tf.zeros_like(predicted_labels),predicted_labels) # considering 0 for real images\n",
    "\n",
    "        ## Applying Backpropogation\n",
    "        ggrad = g_tape.gradient(total_g_loss,self.trainable_variables)\n",
    "        self.g_opt.apply_gradients(zip(ggrad,self.trainable_variables))\n",
    "\n",
    "        return {\"d_loss\":total_d_loss,\"g_loss\":total_g_loss}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da19689",
   "metadata": {
    "id": "2da19689"
   },
   "outputs": [],
   "source": [
    "## crating an instance of sub model class\n",
    "fashgan = FashionGAN(generator,discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13616bd2",
   "metadata": {
    "id": "13616bd2"
   },
   "outputs": [],
   "source": [
    "## compiling model\n",
    "fashgan.compile(g_opt,d_opt,g_loss,d_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47097dc6",
   "metadata": {
    "id": "47097dc6"
   },
   "outputs": [],
   "source": [
    "# Building callback to save image to check progress of training\n",
    "class ModelMonitor(Callback):\n",
    "    def __init__(self,num_img=3,latent_dim=128):\n",
    "        self.num_img = num_img\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "    def on_epoch_end(self,epoch,logs=None):\n",
    "        if not os.path.exists('images/'):\n",
    "            os.makedirs('images/')\n",
    "        if epoch % 10 == 0:\n",
    "            latent_vector = tf.random.uniform((self.num_img,self.latent_dim,1))\n",
    "            gen_img = self.model.generator(latent_vector)\n",
    "            gen_img *= 255 # inverse scaling\n",
    "            gen_img.numpy()\n",
    "\n",
    "            for i in range(self.num_img):\n",
    "                img = array_to_img(gen_img[i])\n",
    "                img.save(os.path.join('images',f'generated_image_{epoch}_{i}.png')) # image folder should be a vailable at the path of notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f747c0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e0f747c0",
    "outputId": "dd12a1b5-c351-435c-fbc9-4f731681d995",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Training GAN\n",
    "hist = fashgan.fit(np.expand_dims(X_ds,axis=3),batch_size=128,epochs=20,callbacks=[ModelMonitor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345f55ee",
   "metadata": {
    "id": "345f55ee"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3daf7f1",
   "metadata": {
    "id": "b3daf7f1"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "celltoolbar": "Raw Cell Format",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
